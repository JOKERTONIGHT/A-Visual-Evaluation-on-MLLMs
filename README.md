# 多模态模型图像性能直观测评

本文旨在测评并对比GPT-4o、Qwen2-VL-72B、InternVL2-pro、MiniCPM-V作为多模态模型在图像输入上的性能（后续评估过程中MiniCPM-V模型demo网页出现不稳定问题，无法正常使用，改为评估LLaVA-OneVision模型）。

与现有的benchmarks不同之处在于，本测评基于较少的测试图像，并将更多地从主观角度以人为评价的形式给出评测结论。测评目的在于通过记录模型回答并人工标注和从多个角度主观分析模型表现，尽可能直观地从用户角度对比并展现模型性能。

## 测评思路

### 测评维度

| 测评维度           | 对应问题举例                                                                                 | 解释                                                                                                                   |
| ------------------ | -------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------- |
| 基础能力           | “请描述此图片”                                                                             | 在不添加其他任何特定提示或处理方向的情况下<br />初步了解模型的性能                                                     |
| OCR能力            | “请列举图中的文字”/<br />“请给出图中特定位置/特定材质上的文字”                           | 测评模型在不同场景下的OCR能力                                                                                          |
| 物体检测与识别能力 | “请列举图中出现的物体”/<br />“图中某物体出现次数”                                        | 测试模型的物体识别能力，<br />包括目前多模态模型较为欠缺的物体计数能力                                                 |
| 人物相关认知识别   | “图中出现了哪些人物”/<br />“图中人物动作/行为/表情”                                      | 区别于一般物体，人物具有更复杂行为表现，<br />需要识别和处理的因素也更多                                               |
| 图像内定位能力     | “请指出某物在图中的位置”/<br />“请说明图中物体的位置关系“                                | 表明模型对于图像信息更加深入的理解，<br />包含图中像素位置信息以及对应物理位置信息                                     |
| 图像基本理解能力   | “图片的可能背景是什么”/<br />“图中可能发生的事件是什么”                                  | 测评模型对于图像的理解，<br />包含基础的物理世界知识和逻辑推理能力                                                     |
| 处理特定图像的能力 | /                                                                                            | 测评对于一些特殊图像的处理性能，如<br />表格/新闻报告/图中图/风格化图像/艺术图像/<br />极端AR（纵横比）图像/遮挡图像等 |
| 图像深度理解能力   | “请基于图片提出特定建议或分析可行性”/<br />“请分析图中隐含信息”/<br />“请解析图片笑点” | 测评模型对于图像的深度理解能力，<br />以及基于图像和其他背景的综合理解分析能力                                         |
| 攻击性问题处理能力 | “请指出图中某物（实际不存在）”/<br />“说明相应内容（存在明显矛盾或错误）”                | 测试图像对于攻击性问题的处理能力                                                                                       |

基于上述测评维度，从各个方面测评模型性能；

另外，一些基础的评价指标例如：幻觉现象作为扣分项、其他模型未提及的图像细节作为加分项、优秀的图像理解作为加分项等

显然，这些测评指标的考察事实上很大程度上取决于具体图像，故下面简单介绍图像选择的一些基本思路

### 图片选取

基于上述测评维度，决定大致选取如下几个方面的图像（图像分类将存在重叠，但选取过程将力争做到覆盖上述测评维度，尽可能具有足够的典型性）：

* 静物（小场景）
* 风景/建筑（大场景）
* 街景
* 人像
* 动态场景
* 特定类型图像
* 复杂场景
* 具有隐藏含义的图像

选取的图像来自相应标签的网络检索

## 测评结果展示

其中添加了一些不同颜色的直观标注：

- 标红的部分表示模型输出的错误内容/幻觉
- 标绿的部分表示准确的回答或其他模型没有注意到的细节
- 标蓝的部分表示具有模型特色的输出或合理的理解

测评详情见：[test_excel](./test_excel.xlsx)

## 测评结论

进行了约50张图片，每张图片对应五个问题（少数图片小于五个问题）的测评，下面结合模型回答在上述测评维度上给出主观评判作为参考（经过考虑，本次测评基于主观用户角度在较少样本下进行直观、定性的分析，故不再使用其他量化手段进行精细评估）

| 测评维度           | 测评结论                                                                                                                                                                                                                                                                                                          |
| ------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 基础能力           | 针对总体描述性问题，模型表现均不错，大部分情况下模型均能较好地描述图片内容。<br />比较来看，GPT-4o在总体描述性问题上表现明显优于其他模型，分析认为<br />这与其大语言模型能力有关，较强的语言模型使得它能够更好地把握描述内容。                                                                                    |
| OCR能力            | 模型OCR能力不及预期。虽然较为简单的OCR任务模型基本都能较好完成，<br />但涉及不规则字体/特殊材质表面/模糊字符等较困难任务时，模型表现不佳。<br />对比而言，LLaVA-OneVision在这一维度上表现较差                                                                                                                     |
| 物体检测与识别能力 | 模型表现一般。对于简单的物体识别检测基本都能较好完成，简单的计数任务<br />也都表现较好。但在特定图像（如风格化图像、场景复杂图像等）上模型均表现不佳<br />其中LLaVA-OneVision在识别类任务上总体表现均不佳，InternVL2表现相对较好                                                                                  |
| 人物相关认知识别   | 人物相关任务上模型不及预期，尤其是涉及人物行为的相对困难识别任务模型表现不佳。<br />对于常规动作模型表现不错，其中GPT-4o和InternVL2相对较好（这里的常规动作指的是：<br />基本动作，如站、坐、行等；与画面整体直接相关动作，如足球比赛中踢球动作）<br />对于非常规的动作（上述情况之外的动作），模型整体表现均不佳 |
| 图像内定位能力     | 模型表现较差，对于图像内绝对位置和相对位置的描述均错误较多                                                                                                                                                                                                                                                        |
| 图像基本理解能力   | 模型均表现较好，对于图像基本信息的理解和推理一般都能较好应对。<br />但其中涉及物理世界知识的理解模型表现一般，尤其是在物理知识基础上进行推理的任务，<br />模型均表现较差                                                                                                                                          |
| 处理特定图像的能力 | 对于不同图像任务模型表现不同，其中较为有代表性的有：<br />GPT-4o在偏文本的图像（如报道、海报等）任务上表现较好<br />对于强风格化图片GPT-4o和IntenVL2表现较好，LLaVA-OneVision也有少数亮眼表现                                                                                                                     |
| 图像深度理解能力   | 模型表现较为参差。其中GPT-4o在此类问题上表现远优于其他模型，<br />Qwen2-VL表现也较好，InternVL2表现一般，LLaVA-OneVision表现较差                                                                                                                                                                                  |
| 攻击性问题处理能力 | GPT-4o表现较好，其他三个模型表现一般                                                                                                                                                                                                                                                                              |

综合来看

- GPT-4o在本次测评中的表现对比其他模型有着明显的优势，尤其是在涉及问题理解、描述性回答、图片深度理解等方面的任务上表现较好。这使得对于一些攻击性问题、带有主观倾向的问题、图片含义分析类问题，它的表现明显优于其他模型。此外，对于大部分问题，GPT-4o的回答往往更符合提问者预期的回答方向。如上方表格中分析的，认为这与其语言模型的较强能力相关
- Qwen2-VL表现中规中矩，没有特别突出的优势项，但在大部分任务上表现均合格，相对于InternVL和LLaVA-OneVision而言，Qwen2-VL在一些理解类问题和背景知识上表现较好
- InternVL2是较为令人惊喜的一个模型。虽然其在理解类任务上表现不及上述两个模型，但在识别类任务上InternVL表现较好。尤其是对于复杂场景中的识别任务和特殊类型识别任务，InternVL展现了较强的识别能力；其在光学字符的识别和人物相关识别人物上的表现也都较好。
- LLaVA-OneVision模型表现不及预期。总体而言模型在识别和理解类任务上表现均不佳，除少数特定图片上模型展现出亮点外，绝大部分任务上LLaVA-OneVision表现不如其他三个模型。

在上述围绕测评维度的对比结论之外，测评过程中还有一些其他的结论：

- **模型易用性**：GPT-4o较好，InternVL2也不错；其他两个模型目前demo都较为简单，使用体验一般
- **模型交互性**：这里指的是模型与用户交互的能力（如提示错误后更正的能力，基于不同提问方式给出不同侧重点回答的能力，理解具体问题细节的能力）。这一点上GPT-4o明显优于其他模型（考虑到其强大的语言能力和较为成熟已经面向海量用户的应用，这一结论是合理的）
- **模型稳定性**：LLaVA-OneVision稳定性较差，回答经常出现过于详细而忽略重点或过于简洁而不够清晰的问题；Qwen2-VL稳定性一般（可能是因为其托管在hugging face页面上的demo请求不稳定，导致经常出现长时间无法响应或突然崩溃的情况，使得输出存在不稳定性）
- **其他**：LLaVA-OneVision经常出现中英文夹杂的情况（在所有提问均是中文的情况下会经常出现使用英文回答的情况；有时会回答中同时有中文和英文的部分），结合之前提到的不稳定问题，认为其或许需要更精细的指令微调训练

总结来说，本次测评中模型表现一般，其中Qwen2-VL、InternVL2和LLaVA-OneVision模型和专有模型GPT-4o相比还存在明显差距。从用户角度来看，当前多模态在实际处理图像任务时表现还有较大的进步空间，相关基于用户反馈改进模型的研究大有可为。当然，测评也体现出GPT-4o在多模态问题上的领先地位，以及InternVL2在识别类任务上的较强性能。
